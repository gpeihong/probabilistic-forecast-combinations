{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbd620-b8b9-4d4f-a3a0-dd5c2c88ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06 Combined Error Metrics\n",
    "## DM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b59e8e-a530-43c7-ba77-ddffe95c8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import properscoring as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f9f4d-d75c-4d10-8027-86238b8fd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiweeks import Week, Year\n",
    "from datetime import date\n",
    "def create_epiweek(date):\n",
    "    return Week.fromdate(date)\n",
    "def create_epiweekplot(epiweek):\n",
    "    epiweek = str(epiweek)\n",
    "    return F'Y{epiweek[:4]}W{epiweek[4:]}'\n",
    "def create_epiweek_fromstr(str):\n",
    "    return Week.fromstring(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d08ba-3aa0-4c53-8c6e-19aa7c2d8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_error_metrics(dataset, target_var):\n",
    "#     pred = dataset.copy()\n",
    "#     model_list = list(pred.columns.values)\n",
    "#     y = pred[[target_var]]\n",
    "#     model_list.remove(target_var)\n",
    "\n",
    "#     error_df = pd.DataFrame()\n",
    "#     #print(model_list)\n",
    "\n",
    "#     for model in model_list:\n",
    "#         model_val = pred[[model]].dropna()\n",
    "#         window_start = model_val.index[0]\n",
    "#         window_end = model_val.index[-1]\n",
    "#         y_val = y.loc[window_start:window_end].copy()\n",
    "\n",
    "#         ## Diebold-Mariano against Naive\n",
    "#         if model == 'naive':\n",
    "#             dm_stat, pvalue = 0, 0\n",
    "#         else:\n",
    "#             dm_stat, pvalue = dm_test(y_val, naive_val, model_val)\n",
    "#             if pvalue < 0.05:\n",
    "#                 pvalue = 'R'\n",
    "#             else:\n",
    "#                 pvalue = 'A'\n",
    "\n",
    "#         error_df.at[model, 'DM'], error_df.at[model, 'pval'] = dm_stat, pvalue\n",
    "\n",
    "#     return error_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b058c7a-b026-42f7-8c7b-5198d97332eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from typing import Sequence, Callable, List, Tuple\n",
    "from math import lgamma, fabs, isnan, nan, exp, log, log1p, sqrt\n",
    "\n",
    "\n",
    "class InvalidParameterException(Exception):\n",
    "    def __init__(self, message: str):\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "class ZeroVarianceException(ArithmeticError):\n",
    "    def __init__(self, message: str):\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "def autocovariance(X: Sequence[float], k: int, mean: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the k-lagged autocovariance for the input iterable.\n",
    "    \"\"\"\n",
    "    return sum((a - mean) * (b - mean) for a, b in zip(islice(X, k, None), X)) / len(X)\n",
    "\n",
    "\n",
    "def log_beta(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the natural logarithm of the beta function computed on\n",
    "    arguments `a` and `b`.\n",
    "    \"\"\"\n",
    "    return lgamma(a) + lgamma(b) - lgamma(a + b)\n",
    "\n",
    "\n",
    "def evaluate_continuous_fraction(\n",
    "    fa: Callable[[int, float], float],\n",
    "    fb: Callable[[int, float], float],\n",
    "    x: float,\n",
    "    *,\n",
    "    epsilon: float = 1e-10,\n",
    "    maxiter: int = 10000,\n",
    "    small: float = 1e-50\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluate a continuous fraction.\n",
    "    \"\"\"\n",
    "    h_prev = fa(0, x)\n",
    "    if fabs(h_prev < small):\n",
    "        h_prev = small\n",
    "\n",
    "    n: int = 1\n",
    "    d_prev: float = 0.0\n",
    "    c_prev: float = h_prev\n",
    "    hn: float = h_prev\n",
    "\n",
    "    while n < maxiter:\n",
    "        a = fa(n, x)\n",
    "        b = fb(n, x)\n",
    "\n",
    "        dn = a + b * d_prev\n",
    "        if fabs(dn) < small:\n",
    "            dn = small\n",
    "\n",
    "        cn = a + b / c_prev\n",
    "        if fabs(cn) < small:\n",
    "            cn = small\n",
    "\n",
    "        dn = 1 / dn\n",
    "        delta_n = cn * dn\n",
    "        hn = h_prev * delta_n\n",
    "\n",
    "        if fabs(delta_n - 1.0) < epsilon:\n",
    "            break\n",
    "\n",
    "        d_prev = dn\n",
    "        c_prev = cn\n",
    "        h_prev = hn\n",
    "\n",
    "        n += 1\n",
    "\n",
    "    return hn\n",
    "\n",
    "\n",
    "def regularized_incomplete_beta(\n",
    "    x: float, a: float, b: float, *, epsilon: float = 1e-10, maxiter: int = 10000\n",
    ") -> float:\n",
    "    if isnan(x) or isnan(a) or isnan(b) or x < 0 or x > 1 or a <= 0 or b <= 0:\n",
    "        return nan\n",
    "\n",
    "    if x > (a + 1) / (2 + b + a) and 1 - x <= (b + 1) / (2 + b + a):\n",
    "        return 1 - regularized_incomplete_beta(\n",
    "            1 - x, b, a, epsilon=epsilon, maxiter=maxiter\n",
    "        )\n",
    "\n",
    "    def fa(n: int, x: float) -> float:\n",
    "        return 1.0\n",
    "\n",
    "    def fb(n: int, x: float) -> float:\n",
    "        if n % 2 == 0:\n",
    "            m = n / 2.0\n",
    "            return (m * (b - m) * x) / ((a + (2 * m) - 1) * (a + (2 * m)))\n",
    "\n",
    "        m = (n - 1.0) / 2.0\n",
    "        return -((a + m) * (a + b + m) * x) / ((a + (2 * m)) * (a + (2 * m) + 1.0))\n",
    "\n",
    "    return exp(\n",
    "        a * log(x) + b * log1p(-x) - log(a) - log_beta(a, b)\n",
    "    ) / evaluate_continuous_fraction(fa, fb, x, epsilon=epsilon, maxiter=maxiter)\n",
    "\n",
    "\n",
    "def dm_test(\n",
    "    P1: Sequence[float],\n",
    "    P2: Sequence[float],\n",
    "    *,\n",
    "    h: int = 1,\n",
    "    one_sided: bool = False,\n",
    "    harvey_correction: bool = True\n",
    ") -> Tuple[float, float]:\n",
    "    r\"\"\"\n",
    "    Performs the Diebold-Mariano test using precomputed loss values.\n",
    "    The null hypothesis is that the two forecasts (`P1`, `P2`) have the same accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P1: Sequence[float]\n",
    "        First loss series.\n",
    "\n",
    "    P2: Sequence[float]\n",
    "        Second loss series.\n",
    "\n",
    "    h: int\n",
    "        The forecast horizon. Default is 1.\n",
    "\n",
    "    one_sided: bool\n",
    "        If set to true, returns the p-value for a one-sided test instead of a two-sided test. Default is false.\n",
    "\n",
    "    harvey_correction: bool\n",
    "        If set to true, uses a modified test statistic as per Harvey, Leybourne and Newbold (1997).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of two values. The first is the test statistic, the second is the p-value.\n",
    "    \"\"\"\n",
    "    if not (len(P1) == len(P2)):\n",
    "        raise InvalidParameterException(\n",
    "            \"Prediction series must have the same length.\"\n",
    "        )\n",
    "\n",
    "    if h <= 0:\n",
    "        raise InvalidParameterException(\n",
    "            \"Invalid parameter for horizon length. Must be a positive integer.\"\n",
    "        )\n",
    "\n",
    "    n = len(P1)\n",
    "    D = [l1 - l2 for l1, l2 in zip(P1, P2)]\n",
    "    mean = sum(D) / n\n",
    "\n",
    "    V_d = 0.0\n",
    "    for i in range(h):\n",
    "        cov = autocovariance(D, i, mean)\n",
    "        if i != 0:\n",
    "            cov *= 2\n",
    "        V_d += cov\n",
    "\n",
    "    V_d /= n\n",
    "\n",
    "    if V_d == 0:\n",
    "        raise ZeroVarianceException(\n",
    "            \"Variance of the DM statistic is zero. Maybe the loss series are identical?\"\n",
    "        )\n",
    "\n",
    "    if harvey_correction:\n",
    "        harvey_adj = sqrt((n + 1 - 2 * h + h * (h - 1) / n) / n)\n",
    "        dmstat = harvey_adj * mean / sqrt(V_d)\n",
    "    else:\n",
    "        dmstat = mean / sqrt(V_d)\n",
    "\n",
    "    pvalue = regularized_incomplete_beta(\n",
    "        (n - 1) / ((n - 1) + dmstat ** 2), 0.5 * (n - 1), 0.5\n",
    "    )\n",
    "\n",
    "    if one_sided:\n",
    "        if dmstat > 0:\n",
    "            pvalue = pvalue\n",
    "        else:\n",
    "            pvalue = 1\n",
    "\n",
    "    return dmstat.item(), pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e034de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps(y_val, y_pred, model, target_var):\n",
    "    np.random.seed(0)\n",
    "    crps_df = pd.DataFrame()\n",
    "    \n",
    "    for epiweek in y_val.index:\n",
    "        \n",
    "        crps_df.at[epiweek, model] = ps.crps_ensemble(y_val.loc[epiweek, target_var], \n",
    "                                                      np.array(y_pred.loc[epiweek], dtype='float64'))\n",
    "    \n",
    "    return crps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c357375-fab1-4e63-99b8-af422d5ac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_diebold_mariano(pred_models_path, pred_combis_path, target_var, model_1, model_2, model_list, combi_list):\n",
    "    \n",
    "    if model_1 in model_list:\n",
    "        pred_model1_file = os.path.join(pred_models_path, f'{model_1}.csv')\n",
    "    else:\n",
    "        pred_model1_file = os.path.join(pred_combis_path, f'{model_1}.csv')\n",
    "        \n",
    "    \n",
    "    if model_2 in model_list:\n",
    "        pred_model2_file = os.path.join(pred_models_path, f'{model_2}.csv')\n",
    "    else:\n",
    "        pred_model2_file = os.path.join(pred_combis_path, f'{model_2}.csv')\n",
    "    \n",
    "    # To get y_val, so use the model 'ar_pure'\n",
    "    ar_pure_file = os.path.join(pred_models_path, 'ar_pure.csv')\n",
    "    ar_pure_val = pd.read_csv(ar_pure_file, parse_dates = [0], dayfirst = True)\n",
    "    ar_pure_val['epiweek'] = ar_pure_val['epiweek'].apply(create_epiweek_fromstr)\n",
    "    ar_pure_val = ar_pure_val.set_index('epiweek')\n",
    "    y_val = ar_pure_val[[target_var]]\n",
    "    \n",
    "    if os.path.isfile(pred_model1_file) and os.path.isfile(pred_model2_file):\n",
    "        model_1_val = pd.read_csv(pred_model1_file, parse_dates = [0], dayfirst = True)  \n",
    "        model_1_val['epiweek'] = model_1_val['epiweek'].apply(create_epiweek_fromstr)\n",
    "        model_1_val = model_1_val.set_index('epiweek')\n",
    "        model_1_val_crps = crps(y_val.copy(), model_1_val.iloc[:,1:].copy(), model_1, target_var)\n",
    "\n",
    "        model_2_val = pd.read_csv(pred_model2_file, parse_dates = [0], dayfirst = True)  \n",
    "        model_2_val['epiweek'] = model_2_val['epiweek'].apply(create_epiweek_fromstr)\n",
    "        model_2_val = model_2_val.set_index('epiweek')\n",
    "        model_2_val_crps = crps(y_val.copy(), model_2_val.iloc[:,1:].copy(), model_2, target_var)\n",
    "        \n",
    "\n",
    "\n",
    "    return model_1_val_crps, model_2_val_crps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68460a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pvalue(pvalue):\n",
    "    if pvalue < 0.05:\n",
    "    #non-equivalent, i.e. we reject the null hypothesis that both models have equal predictive capability\n",
    "    #non-equivalence in RED\n",
    "        pvalue = -1\n",
    "    else:\n",
    "    #pvalue > 0.05\n",
    "    #equivalent, i.e. we accept the null hypothesis that both models have equal predictive capability\n",
    "    #not enough evidence to show that one model predictive better than the other\n",
    "        pvalue = 1\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_diebold_mariano(dataset, target_var, step_name):\n",
    "    \n",
    "#     pred_models_path = os.path.join(pred_directory_path,step_name)\n",
    "#     if os.path.isdir(pred_models_path):\n",
    "#         for model_name in os.listdir(pred_models_path): # 'model_name' here includes the '.csv'\n",
    "#             pred_file = os.path.join(pred_models_path, model_name)\n",
    "#             model = model_name[0:-4]\n",
    "#             if os.path.isfile(pred_file):\n",
    "#                 y_pred = pd.read_csv(pred_file, parse_dates = [0], dayfirst = True)  \n",
    "#                 y_pred['epiweek'] = y_pred['epiweek'].apply(create_epiweek_fromstr)\n",
    "#                 y_pred = y_pred.set_index('epiweek') \n",
    "    \n",
    "#     model_list = list(pred.columns.values)\n",
    "#     y = pred[[target_var]]\n",
    "#     model_list.remove(target_var)\n",
    "\n",
    "#     diebold_mariano_dmstat_df = pd.DataFrame(index=model_list, columns=model_list)\n",
    "#     diebold_mariano_pvalue_df = pd.DataFrame(index=model_list, columns=model_list)\n",
    "    \n",
    "#     for model_1 in model_list:\n",
    "#         for model_2 in model_list:\n",
    "#             if model_1 == model_2:\n",
    "#                 dm_stat, pvalue = 0, 0\n",
    "#             else:\n",
    "#                 if pd.isna(diebold_mariano_pvalue_df.loc[model_2, model_1]):\n",
    "#                     model_1_val, model_2_val, y_val = prepare_diebold_mariano(pred, target_var, model_1, model_2)\n",
    "#                     dm_stat, pvalue = dm_test(y_val, model_1_val, model_2_val, one_sided=True)\n",
    "#                     pvalue = evaluate_pvalue(pvalue)\n",
    "#                 else:\n",
    "#                     dm_stat, pvalue = 0, 0\n",
    "#             diebold_mariano_dmstat_df.at[model_1, model_2], diebold_mariano_pvalue_df.at[model_1, model_2] = dm_stat, pvalue\n",
    "#     return diebold_mariano_dmstat_df, diebold_mariano_pvalue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d512ac0-8694-479e-b44d-37c18e404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diebold_mariano(target_var, pred_directory, pred_combi_directory):\n",
    "    pred_directory_path = os.path.join(target_var, pred_directory)\n",
    "    pred_combi_directory_path = os.path.join(target_var, pred_combi_directory)\n",
    "    \n",
    "    for step_name in os.listdir(pred_directory_path):\n",
    "        pred_models_path = os.path.join(pred_directory_path,step_name)\n",
    "        pred_combis_path = os.path.join(pred_combi_directory_path,step_name)\n",
    "        if os.path.isdir(pred_models_path):\n",
    "            model_combi_list = []\n",
    "            model_list = []\n",
    "            combi_list = []\n",
    "            for model_name in os.listdir(pred_models_path): # 'model_name' here includes the '.csv'\n",
    "#                 pred_file = os.path.join(pred_models_path, model_name) \n",
    "                model = model_name[0:-4]\n",
    "                model_combi_list.append(model)\n",
    "                model_list.append(model)\n",
    "            for combi_name in os.listdir(pred_combis_path):\n",
    "#                 pred_file = os.path.join(pred_combis_path, combi_name)\n",
    "                combi = combi_name[0:-4]\n",
    "                model_combi_list.append(combi)\n",
    "                combi_list.append(combi)\n",
    "                \n",
    "                \n",
    "            diebold_mariano_dmstat_df = pd.DataFrame(index=model_combi_list, columns=model_combi_list)\n",
    "            diebold_mariano_pvalue_df = pd.DataFrame(index=model_combi_list, columns=model_combi_list)\n",
    "\n",
    "            for model_1 in model_combi_list:\n",
    "                for model_2 in model_combi_list:\n",
    "                    if model_1 == model_2:\n",
    "                        dm_stat, pvalue = 0, 0\n",
    "                    else:\n",
    "                        if pd.isna(diebold_mariano_pvalue_df.loc[model_2, model_1]):\n",
    "                            model_1_val_crps, model_2_val_crps = prepare_diebold_mariano(pred_models_path, pred_combis_path, target_var, model_1, model_2, model_list, combi_list)\n",
    "                            dm_stat, pvalue = dm_test(np.array(model_1_val_crps), np.array(model_2_val_crps), one_sided=True)\n",
    "                            pvalue = evaluate_pvalue(pvalue)\n",
    "                        else:\n",
    "                            dm_stat, pvalue = 0, 0\n",
    "                    diebold_mariano_dmstat_df.at[model_1, model_2], diebold_mariano_pvalue_df.at[model_1, model_2] = dm_stat, pvalue\n",
    "\n",
    "\n",
    "\n",
    "            dmstat_path = os.path.join(target_var, 'dmstat')\n",
    "            if not os.path.exists(dmstat_path):\n",
    "                os.makedirs(dmstat_path)\n",
    "            diebold_mariano_dmstat_df.to_csv(os.path.join(dmstat_path, f'{step_name}.csv'))\n",
    "\n",
    "            pvalue_path = os.path.join(target_var, 'pvalue')\n",
    "            if not os.path.exists(pvalue_path):\n",
    "                os.makedirs(pvalue_path)\n",
    "            diebold_mariano_pvalue_df.to_csv(os.path.join(pvalue_path, f'{step_name}.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a0916-8c33-4078-9d6f-295ffa700aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_generate_diebold_mariano(target_variables_file, pred_directory, pred_combi_directory):\n",
    "    target_variables = []\n",
    "    with open(target_variables_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove linebreak which is the last character of the string\n",
    "            target_variable = line[:-1]\n",
    "            # Add item to the list\n",
    "            target_variables.append(target_variable)\n",
    "    print(target_variables)\n",
    "\n",
    "    Parallel(n_jobs=-1, verbose=51)(delayed(generate_diebold_mariano)(target_var, \n",
    "                                                                    pred_directory, \n",
    "                                                                    pred_combi_directory) for target_var in target_variables)\n",
    "    \n",
    "full_generate_diebold_mariano('target_variables_new.txt', 'pred','combi_samples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
