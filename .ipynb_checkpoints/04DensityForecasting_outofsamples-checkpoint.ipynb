{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbd6566-5691-47ab-a0f7-40c35851a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 04 (1)Evaluating individual models using metrics and (2) calcualte most recent errors for combinatnions weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5381f64-c539-4443-a403-5a6864ec3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import properscoring as ps\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff970b9d-c903-44ea-8f36-3f5c0151a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiweeks import Week, Year\n",
    "from datetime import date\n",
    "def create_epiweek(date):\n",
    "    return Week.fromdate(date)\n",
    "def create_epiweekplot(epiweek):\n",
    "    epiweek = str(epiweek)\n",
    "    return F'Y{epiweek[:4]}W{epiweek[4:]}'\n",
    "def filename_to_epiweek(filename):\n",
    "    return Week.fromstring(F'{filename[:4]}W{filename[4:6]}')\n",
    "def create_epiweek_fromstr(str):\n",
    "    return Week.fromstring(str)\n",
    "def create_epiweek_fromint(int):\n",
    "    return Week.fromstring(str(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02131836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import properscoring as ps\n",
    "\n",
    "def outofsamples_crps(target_var, pred_directory, crps_directory, comparison_operator):\n",
    "    model_names_order = ['naive', 'historymean', 'ar_pure', 'ar_env', 'ridge', 'lasso', 'alasso', 'sgl',\n",
    "                 'elasticnet', 'purefactor', 'knn', 'xgboost']\n",
    "    # Paths setup\n",
    "    pred_directory_path = os.path.join(target_var, pred_directory)\n",
    "    crps_directory_path = os.path.join(target_var, crps_directory)\n",
    "    \n",
    "    if not os.path.exists(crps_directory_path):\n",
    "        os.makedirs(crps_directory_path)\n",
    "    \n",
    "    for step_name in os.listdir(pred_directory_path):\n",
    "        pred_models_path = os.path.join(pred_directory_path, step_name)\n",
    "        if os.path.isdir(pred_models_path):\n",
    "            full_crps_df = pd.DataFrame()\n",
    "            \n",
    "            for model_name in os.listdir(pred_models_path):\n",
    "                pred_file = os.path.join(pred_models_path, model_name)\n",
    "                if os.path.isfile(pred_file):\n",
    "                    y_pred = pd.read_csv(pred_file, parse_dates=[0], dayfirst=True) # Ill-disease L8_S9 lasso.csv has some unseen format isuue\n",
    "                    model_crps_df = pd.DataFrame()\n",
    "\n",
    "                    for filename in y_pred['epiweek']:\n",
    "                        # Apply the comparison operator\n",
    "                        if comparison_operator == '<=':\n",
    "                            y_pred_new = y_pred[y_pred['epiweek'] <= filename]\n",
    "                        elif comparison_operator == '==':\n",
    "                            y_pred_new = y_pred[y_pred['epiweek'] == filename]\n",
    "                        else:\n",
    "                            raise ValueError(\"Invalid comparison_operator: must be '<=' or '=='\")\n",
    "                        \n",
    "                        y_pred_outofsamples = pd.DataFrame(y_pred_new.iloc[:, 1:], dtype='float64')\n",
    "                        \n",
    "                        # Calculate CRPS for this epiweek\n",
    "                        crps_values = []\n",
    "                        for i in range(len(y_pred_outofsamples)):\n",
    "                            crps = ps.crps_ensemble(\n",
    "                                y_pred_outofsamples.iloc[i, 0], y_pred_outofsamples.iloc[i, 1:]\n",
    "                            )\n",
    "                            crps_values.append(crps)\n",
    "                        \n",
    "                        mean_crps = np.mean(crps_values)\n",
    "                        model_crps_df.at[filename, model_name[:-4]] = mean_crps\n",
    "                    \n",
    "                    full_crps_df = pd.concat([full_crps_df, model_crps_df], axis=1)\n",
    "            full_crps_df = full_crps_df[model_names_order]\n",
    "            full_crps_df.sort_index(inplace=True)\n",
    "            full_crps_df.to_csv(os.path.join(crps_directory_path, f'{step_name}.csv'))\n",
    "\n",
    "def generate_full_crps_P1(target_var, pred_directory, crps_directory_P1):\n",
    "    model_names_order = ['naive', 'historymean', 'ar_pure', 'ar_env', 'ridge', 'lasso', 'alasso', 'sgl',\n",
    "                 'elasticnet', 'purefactor', 'knn', 'xgboost']\n",
    "    # Paths setup\n",
    "    pred_directory_path = os.path.join(target_var, pred_directory)\n",
    "    crps_directory_path = os.path.join(target_var, crps_directory_P1)\n",
    "    \n",
    "    if not os.path.exists(crps_directory_path):\n",
    "        os.makedirs(crps_directory_path)\n",
    "    \n",
    "    for step_name in os.listdir(pred_directory_path):\n",
    "        pred_models_path = os.path.join(pred_directory_path, step_name)\n",
    "        if os.path.isdir(pred_models_path):\n",
    "            full_crps_df = pd.DataFrame()\n",
    "            for model_name in os.listdir(pred_models_path):\n",
    "                pred_file = os.path.join(pred_models_path, model_name)\n",
    "                if os.path.isfile(pred_file):\n",
    "                    y_pred = pd.read_csv(pred_file, parse_dates=[0], dayfirst=True)\n",
    "                    index = y_pred['epiweek'].unique()\n",
    "                    \n",
    "                    full_crps_df = pd.DataFrame(1, index=index, columns=model_names_order)\n",
    "                    full_crps_df.sort_index(inplace=True)\n",
    "                    \n",
    "                    full_crps_df.to_csv(os.path.join(crps_directory_path, f'{step_name}.csv'))\n",
    "                    break  # We only need to do this once per step_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559fc1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular disease', 'Chronic respiratory disease', 'Factors influencing health status and contact with health services', 'Digestive disease', 'Endocrine disorders', 'Malignant neoplasms', 'Diabetes mellitus', 'Genitourinary disorders', 'Musculoskeletal disease', 'Infectious and Parasitic Diseases', 'Neurological and sense disorders', 'Oral Diseases', 'Other neoplasms', 'Respiratory Infection', 'Skin diseases']\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:  2.6min remaining: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  15 | elapsed:  2.6min remaining: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  2.9min remaining:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  15 | elapsed:  2.9min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:  2.9min remaining:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  15 | elapsed:  2.9min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  2.9min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:  2.9min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  2.9min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed:  2.9min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  2.9min remaining:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed:  4.7min remaining:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:   10.7s remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  15 | elapsed:   10.9s remaining:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:   13.6s remaining:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  15 | elapsed:   13.8s remaining:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:   13.9s remaining:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  15 | elapsed:   13.9s remaining:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   14.0s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:   14.0s remaining:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:   14.0s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed:   14.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:   14.2s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed:   20.2s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  15 | elapsed:    0.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    0.4s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  15 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:    0.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  15 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "def run_crps(target_variables_file, pred_directory, crps_directory_P3, crps_directory_P2, crps_directory_P1):\n",
    "    target_variables = []\n",
    "    with open(target_variables_file, 'r') as file:\n",
    "        for line in file:\n",
    "            target_variable = line.strip()\n",
    "            target_variables.append(target_variable)\n",
    "    \n",
    "    print(target_variables)\n",
    "    \n",
    "    Parallel(n_jobs=-1, verbose=51)(\n",
    "        delayed(outofsamples_crps)(target_var, pred_directory, crps_directory_P3, '<=') \n",
    "        for target_var in target_variables\n",
    "    )\n",
    "    \n",
    "    Parallel(n_jobs=-1, verbose=51)(\n",
    "        delayed(outofsamples_crps)(target_var, pred_directory, crps_directory_P2, '==') \n",
    "        for target_var in target_variables\n",
    "    )\n",
    "    \n",
    "    Parallel(n_jobs=-1, verbose=51)(\n",
    "        delayed(generate_full_crps_P1)(target_var, pred_directory, crps_directory_P1) \n",
    "        for target_var in target_variables\n",
    "    )\n",
    "\n",
    "# Execute the function\n",
    "run_crps('target_variables_new.txt', 'pred', 'full_crps_P3', 'full_crps_P2', 'full_crps_P1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4343a3",
   "metadata": {},
   "source": [
    "## calculate crps/log score for submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44db44ce-f33d-4d5b-998b-872656a42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps(y_val, y_pred, model, target_var):\n",
    "    np.random.seed(0)\n",
    "    crps_df = pd.DataFrame()\n",
    "    \n",
    "    for epiweek in y_val.index:\n",
    "        \n",
    "        crps_df.at[epiweek, model] = ps.crps_ensemble(y_val.loc[epiweek, target_var], \n",
    "                                                      np.array(y_pred.loc[epiweek], dtype='float64'))\n",
    "    \n",
    "    return crps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eeb89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dss(y_val, y_pred, model, target_var):\n",
    "#     dss_df = pd.DataFrame()\n",
    "\n",
    "#     for epiweek in y_val.index:\n",
    "#         mean = np.mean(y_pred.loc[epiweek])\n",
    "\n",
    "#         # Calculate the variance (sample variance)\n",
    "#         variance = np.var(y_pred.loc[epiweek], ddof=1)\n",
    "#         variance = np.maximum(variance, 1e-6)\n",
    "#         # Calculate DSS for the current epiweek and model\n",
    "#         dss = ((y_val.loc[epiweek, target_var] - mean)**2 / variance) + np.log(variance)\n",
    "#         dss_df.at[epiweek, model] = dss\n",
    "\n",
    "#     return dss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a80c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(y_val, y_pred, model, target_var):\n",
    "    log_df = pd.DataFrame()\n",
    "    \n",
    "    for epiweek in y_val.index:\n",
    "        samples = np.array(y_pred.loc[epiweek], dtype='float64')\n",
    "        kde = gaussian_kde(samples)\n",
    "        prob_density = kde(y_val.loc[epiweek, target_var])\n",
    "        prob_density = max(prob_density, 1e-9)  # To avoid log(0)\n",
    "\n",
    "        log_score = -np.log(float(prob_density))\n",
    "        log_df.at[epiweek, model] = log_score        \n",
    "    \n",
    "    return log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2921477e-1713-4543-b1ec-718dda4ad56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disease_crps(target_var, pred_directory, density_forecast_directory):\n",
    "    model_names_order = ['naive', 'historymean', 'ar_pure', 'ar_env', 'ridge', 'lasso', 'alasso', 'sgl',\n",
    "                 'elasticnet', 'purefactor', 'knn', 'xgboost']\n",
    "    pred_directory_path = os.path.join(target_var, pred_directory)\n",
    "    density_forecast_directory_path = os.path.join(target_var, density_forecast_directory)\n",
    "    if not os.path.exists(density_forecast_directory_path):\n",
    "        os.makedirs(density_forecast_directory_path)\n",
    "    \n",
    "    for step_name in os.listdir(pred_directory_path):\n",
    "        pred_models_path = os.path.join(pred_directory_path,step_name)\n",
    "        \n",
    "        if os.path.isdir(pred_models_path):\n",
    "            model_list = []\n",
    "            crps_density_forecast_df = pd.DataFrame()\n",
    "            log_density_forecast_df = pd.DataFrame()\n",
    "            for model_name in os.listdir(pred_models_path): # 'model_name' here includes the '.csv'\n",
    "                pred_file = os.path.join(pred_models_path, model_name)\n",
    "                model = model_name[0:-4]\n",
    "                \n",
    "                if os.path.isfile(pred_file):\n",
    "                    model_list.append(model) # to store the models' names\n",
    "                    y_pred = pd.read_csv(pred_file, parse_dates = [0], dayfirst = True)  \n",
    "                    y_pred['epiweek'] = y_pred['epiweek'].apply(create_epiweek_fromstr)\n",
    "                    y_pred = y_pred.set_index('epiweek')\n",
    "\n",
    "                    crps_col = crps(y_pred[[target_var]].copy(), y_pred.iloc[:,1:].copy(), model, target_var)\n",
    "                    crps_density_forecast_df = pd.concat([crps_density_forecast_df, crps_col], axis=1)\n",
    "                    log_col = log(y_pred[[target_var]].copy(), y_pred.iloc[:,1:].copy(), model, target_var)\n",
    "                    log_density_forecast_df = pd.concat([log_density_forecast_df, log_col], axis=1)\n",
    "\n",
    "\n",
    "            crps_density_forecast_df.columns = model_list\n",
    "            log_density_forecast_df.columns = model_list\n",
    "            \n",
    "            crps_density_forecast_df = crps_density_forecast_df[model_names_order]\n",
    "            log_density_forecast_df = log_density_forecast_df[model_names_order]\n",
    "\n",
    "            density_forecast_output = pd.DataFrame()\n",
    "            for col in crps_density_forecast_df.columns:\n",
    "                density_forecast_output.at[col, 'crps_DENSITY_FORECAST'] = crps_density_forecast_df[col].mean()\n",
    "                density_forecast_output.at[col, 'log_DENSITY_FORECAST'] = log_density_forecast_df[col].mean()\n",
    "            density_forecast_output.to_csv(os.path.join(density_forecast_directory_path, F'{step_name}.csv'))\n",
    "            \n",
    "#disease_crps('Cardiovascular disease', 'pred', 'variance', 'density_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59f5dc4d-d456-4a88-8448-88cb6544d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular disease', 'Chronic respiratory disease', 'Factors influencing health status and contact with health services', 'Digestive disease', 'Endocrine disorders', 'Malignant neoplasms', 'Diabetes mellitus', 'Genitourinary disorders', 'Musculoskeletal disease', 'Infectious and Parasitic Diseases', 'Neurological and sense disorders', 'Oral Diseases', 'Other neoplasms', 'Respiratory Infection', 'Skin diseases']\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:   13.4s remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  15 | elapsed:   13.5s remaining:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:   16.5s remaining:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  15 | elapsed:   16.6s remaining:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:   16.6s remaining:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  15 | elapsed:   16.8s remaining:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   16.9s remaining:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:   16.9s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:   17.0s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed:   17.0s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:   17.1s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed:   25.1s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   25.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   25.4s finished\n"
     ]
    }
   ],
   "source": [
    "## This function calculates the density forecast based on the output prediction forecast and calculated variance\n",
    "\n",
    "def run_full_crps(target_variables_file, pred_directory, density_forecast_directory):\n",
    "    target_variables = []\n",
    "    with open(target_variables_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove linebreak which is the last character of the string\n",
    "            target_variable = line[:-1]\n",
    "            # Add item to the list\n",
    "            target_variables.append(target_variable)\n",
    "    print(target_variables)\n",
    "    Parallel(n_jobs=-1, verbose=51)(delayed(disease_crps)(target_var, pred_directory, density_forecast_directory) for target_var in target_variables)\n",
    "    \n",
    "run_full_crps('target_variables_new.txt', 'pred', 'density_forecast_metrics')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
